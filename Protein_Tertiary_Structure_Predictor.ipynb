{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Protein Tertiary Structure Predictor.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhuchunlin1995/Deep-Learning/blob/master/Protein_Tertiary_Structure_Predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "CqqMAqQMBI3l",
        "colab_type": "code",
        "outputId": "ffedabf6-b8b0-4e4e-898f-852479ecf952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "r0E_HFgcBPVx",
        "colab_type": "code",
        "outputId": "d43d2966-e2cb-40a8-f7e7-f2549404daa6",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8f0480c2-5000-4117-8eba-b520ac27b787\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-8f0480c2-5000-4117-8eba-b520ac27b787\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train_fold_1.pkl to train_fold_1.pkl\n",
            "User uploaded file \"train_fold_1.pkl\" with length 119801324 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6ebbIcqYVAX6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def encoder_initialize(corpus):\n",
        "  if type(corpus) is str:\n",
        "    corpus = list(corpus)\n",
        "  corpus_arr = np.expand_dims(corpus, 1) # n x 1 array\n",
        "  encoder = preprocessing.OneHotEncoder()\n",
        "  encoder.fit(corpus_arr)\n",
        "  return encoder\n",
        "\n",
        "# dictionary for amino acid and local structure type\n",
        "AA_CHR = 'ACDEFGHIKLMNPQRSTVWXY'\n",
        "Q8_CHR = 'GHITEBS-'\n",
        "aa_encoder = encoder_initialize(AA_CHR)\n",
        "q8_encoder = encoder_initialize(Q8_CHR)\n",
        "\n",
        "def encoding(seq, encoder):\n",
        "  #the encoding matrix is in 21 * n and 8 * n\n",
        "  if type(seq) is str:\n",
        "    seq = list(seq)\n",
        "  seq_arr = np.expand_dims(seq, 1)\n",
        "  oh_encoded = encoder.transform(seq_arr).toarray()\n",
        "  return oh_encoded\n",
        "\n",
        "\n",
        "def colToMat(x): \n",
        "  #1xn np array passed in\n",
        "  return np.tile(x.transpose(), (x.shape[1],1,1))\n",
        "\n",
        "def colToMatTranspose(x):\n",
        "  x = colToMat(x)\n",
        "  X_T = np.transpose(x)\n",
        "  return X_T  \n",
        "\n",
        "\n",
        "def sequencesToVolume(a, aa_encoder, q, q8_encoder, msa): \n",
        "  #MSA of length 21nx\n",
        "  #a of length 1xn string\n",
        "  #t encoding returns nx21\n",
        "  #q8 . of length 1xn\n",
        "  n = len(a)\n",
        "  A_new = encoding(a, aa_encoder).transpose()\n",
        "  Q_new = encoding(q, q8_encoder).transpose()\n",
        "  \n",
        "  msa_mat1 = colToMat(msa)\n",
        "  msa_mat2 = msa_mat1.transpose((1,0,2))\n",
        "\n",
        "  aa_mat1 = colToMat(A_new)\n",
        "  aa_mat2 = aa_mat1.transpose((1,0,2))\n",
        "\n",
        "  q8_mat1 = colToMat(Q_new)\n",
        "  q8_mat2 = q8_mat1.transpose((1,0,2))\n",
        "\n",
        "  final_matrix = np.concatenate([msa_mat2, msa_mat1, aa_mat2, aa_mat1, q8_mat2, q8_mat1], axis=2)\n",
        "  \n",
        "  return A_new, Q_new, final_matrix\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dIWdg9LkQZQ0",
        "colab_type": "code",
        "outputId": "25180df3-7d81-4d3f-d955-427250651ca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1258
        }
      },
      "cell_type": "code",
      "source": [
        "train_matrix,train_aa_seq, train_ss_seq, train_casp_id, train_msas, train_phis, train_psis = [], [], [], [], [], [], []\n",
        "for i in range(1):\n",
        "  #load i+1\n",
        "  fold = i+1\n",
        "  data_loc = '/content/train_fold_{}.pkl'.format(fold)\n",
        "  datafile = data_loc\n",
        "  with open(datafile, 'rb') as f:\n",
        "    train_input_f =  pickle.load(f)\n",
        "  indices, pdbs, length_aas, pdb_aas, q8s, dcalphas, psis, phis, msas = train_input_f\n",
        "  # number of data pts in train fold i+1\n",
        "  print(\"num of data pts in train fold {}\".format(fold), len(pdbs))\n",
        "  for j in range(len(length_aas)):\n",
        "    A, Q, matrix = sequencesToVolume(pdb_aas[j], aa_encoder, q8s[j], q8_encoder, np.array(msas[j]))\n",
        "    print(matrix.shape)\n",
        "    train_aa_seq.append(A)\n",
        "    train_ss_seq.append(Q)\n",
        "    train_phis.append(phis[j])\n",
        "    train_psis.append(psis[j])\n",
        "    train_msas.append(np.array(msas[j]))\n",
        "    train_matrix.append(matrix)\n",
        "    \n",
        "    print(\"number of sample added: {} \".format(j))\n",
        "    print(\"shape of matrix is: {}\".format(matrix.shape))\n",
        "print(len(train_aa_seq), len(train_ss_seq), len(train_psis), len(train_phis), len(train_msas), len(train_matrix))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num of data pts in train fold 1 335\n",
            "(234, 234, 100)\n",
            "number of sample added: 0 \n",
            "shape of matrix is: (234, 234, 100)\n",
            "(204, 204, 100)\n",
            "number of sample added: 1 \n",
            "shape of matrix is: (204, 204, 100)\n",
            "(94, 94, 100)\n",
            "number of sample added: 2 \n",
            "shape of matrix is: (94, 94, 100)\n",
            "(79, 79, 100)\n",
            "number of sample added: 3 \n",
            "shape of matrix is: (79, 79, 100)\n",
            "(189, 189, 100)\n",
            "number of sample added: 4 \n",
            "shape of matrix is: (189, 189, 100)\n",
            "(71, 71, 100)\n",
            "number of sample added: 5 \n",
            "shape of matrix is: (71, 71, 100)\n",
            "(399, 399, 100)\n",
            "number of sample added: 6 \n",
            "shape of matrix is: (399, 399, 100)\n",
            "(276, 276, 100)\n",
            "number of sample added: 7 \n",
            "shape of matrix is: (276, 276, 100)\n",
            "(106, 106, 100)\n",
            "number of sample added: 8 \n",
            "shape of matrix is: (106, 106, 100)\n",
            "(91, 91, 100)\n",
            "number of sample added: 9 \n",
            "shape of matrix is: (91, 91, 100)\n",
            "(303, 303, 100)\n",
            "number of sample added: 10 \n",
            "shape of matrix is: (303, 303, 100)\n",
            "(93, 93, 100)\n",
            "number of sample added: 11 \n",
            "shape of matrix is: (93, 93, 100)\n",
            "(47, 47, 100)\n",
            "number of sample added: 12 \n",
            "shape of matrix is: (47, 47, 100)\n",
            "(142, 142, 100)\n",
            "number of sample added: 13 \n",
            "shape of matrix is: (142, 142, 100)\n",
            "(352, 352, 100)\n",
            "number of sample added: 14 \n",
            "shape of matrix is: (352, 352, 100)\n",
            "(35, 35, 100)\n",
            "number of sample added: 15 \n",
            "shape of matrix is: (35, 35, 100)\n",
            "(231, 231, 100)\n",
            "number of sample added: 16 \n",
            "shape of matrix is: (231, 231, 100)\n",
            "(25, 25, 100)\n",
            "number of sample added: 17 \n",
            "shape of matrix is: (25, 25, 100)\n",
            "(307, 307, 100)\n",
            "number of sample added: 18 \n",
            "shape of matrix is: (307, 307, 100)\n",
            "(95, 95, 100)\n",
            "number of sample added: 19 \n",
            "shape of matrix is: (95, 95, 100)\n",
            "(126, 126, 100)\n",
            "number of sample added: 20 \n",
            "shape of matrix is: (126, 126, 100)\n",
            "(91, 91, 100)\n",
            "number of sample added: 21 \n",
            "shape of matrix is: (91, 91, 100)\n",
            "(236, 236, 100)\n",
            "number of sample added: 22 \n",
            "shape of matrix is: (236, 236, 100)\n",
            "(79, 79, 100)\n",
            "number of sample added: 23 \n",
            "shape of matrix is: (79, 79, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B8ghPoGnrwX2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# load protein names\n",
        "testfile = \"../content/train_fold_1.csv\"\n",
        "test_input = pd.read_csv(testfile, header=None)\n",
        "protein_names = np.array(test_input.iloc[:,1])\n",
        "protein_len = np.array(test_input.iloc[:,2])\n",
        "\n",
        "# concatenate all output to one-dimensional\n",
        "all_data = []\n",
        "all_names = []\n",
        "for i, pname in enumerate(protein_names):\n",
        "    dist_flat = dist[i].ravel()\n",
        "    array = np.concatenate([dist_flat, psi[i], phi[i]])\n",
        "    all_data.append(array)\n",
        "\n",
        "    length = protein_len[i]\n",
        "    dist_names = [\"{}_d_{}_{}\".format(pname, i + 1, j + 1) for i in range(length) for\n",
        "            j in range(length)]\n",
        "\n",
        "    psi_names = [\"{}_psi_{}\".format(pname, i + 1) for i in range(length)]\n",
        "    phi_names = [\"{}_phi_{}\".format(pname, i + 1) for i in range(length)]\n",
        "    row_names = np.array(dist_names + psi_names + phi_names)\n",
        "    all_names.append(row_names)\n",
        "\n",
        "all_data = np.concatenate(all_data)\n",
        "all_names = np.concatenate(all_names)\n",
        "output = {\"Id\": all_names, \"Predicted\": all_data}\n",
        "output = pd.DataFrame(output)\n",
        "output.to_csv(\"SAVE_PATH\", index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}