{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhuchunlin1995/Deep-Learning/blob/master/image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "6SD-AONjrguR",
        "colab_type": "code",
        "outputId": "c0e296e9-be36-47fe-db9e-25469e5fd6e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "#download the CIFAR10 dataset for image classification.\n",
        "import torch, torchvision\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "transform = torchvision.transforms.Compose( [torchvision.transforms.ToTensor(),torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)\n",
        "\n",
        "#preprocess trainset.\n",
        "dataset = []\n",
        "#flat dataset\n",
        "for data in trainset:\n",
        "  tmp = []\n",
        "  tmp.append(data[0].numpy().ravel())\n",
        "  tmp.append(data[1])\n",
        "  dataset.append(tmp)\n",
        "\n",
        "#split dataset into training set and validation set\n",
        "random.shuffle(dataset)\n",
        "valiset = dataset[:5000]\n",
        "trainset = dataset[5000:]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
            "Files already downloaded and verified\n",
            "3072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EtTKFOi5g1IJ",
        "colab_type": "code",
        "outputId": "8fd89a02-4bc7-48b6-a3d6-eea5f62e5170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "  \n",
        "  \"\"\"we will initialize the number of neuron for every hidden layer as 2/3 size of the input layer,\n",
        "    and assume the output layer will only contains only one neuron\"\"\"\n",
        "  def __init__(self, layer_dimensions):\n",
        "    \n",
        "    #initialize weights and bias\n",
        "    self.parameters = {}\n",
        "    self.num_layers = len(layer_dimensions)\n",
        "    for l in range (1, self.num_layers):\n",
        "      eps = np.sqrt(2.0 / (layer_dimensions[l] + layer_dimensions[l - 1]))\n",
        "      self.parameters[\"W\" + str(l)] = np.random.randn(layer_dimensions[l], layer_dimensions[l - 1]) * eps\n",
        "      self.parameters[\"b\" + str(l)] = np.zeros((layer_dimensions[l], 1)) + 0.01\n",
        "   \n",
        "  def affineFoward(self, A, W, b):\n",
        "    forward = np.dot(A, W) + b\n",
        "    return forward\n",
        "    \n",
        "  def activationForward(self, A):\n",
        "    # use relu function as activation function\n",
        "    A = np.maximum(0, A)\n",
        "    return A\n",
        "  \n",
        "  def costFunction(self, AL, y):\n",
        "    #use softmax function to normalize AL first\n",
        "    \n",
        "    \n",
        "  \n",
        "  \n",
        "  def affineBackward(self, dA_prev, cache):\n",
        "  \n",
        "  \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "  \n",
        "  \"\"\"we will initialize the number of neuron for every hidden layer as 2/3 size of the input layer,\n",
        "    and assume the output layer will only contains only one neuron\"\"\"\n",
        "  \n",
        "  layer_dimensions = [3072, 2048, 1365, 1]\n",
        "  nn = NeuralNetwork(layer_dimensions)\n",
        "  print(nn.parameters[\"b1\"])\n",
        "      \n",
        "    "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.01]\n",
            " [0.01]\n",
            " [0.01]\n",
            " ...\n",
            " [0.01]\n",
            " [0.01]\n",
            " [0.01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dn9JRbhSgviw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    }
  ]
}